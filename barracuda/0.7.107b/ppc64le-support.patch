--- ksw.c
+++ ksw.c
@@ -26,7 +26,7 @@
 #ifndef _NO_SSE2
 #include <stdlib.h>
 #include <stdint.h>
-#include <emmintrin.h>
+#include <vec128int.h>
 #include "ksw.h"
 
 #ifdef __GNUC__
@@ -98,32 +98,32 @@
 	__m128i zero, gapoe, gape, shift, *H0, *H1, *E, *Hmax;
 
 #define __max_16(ret, xx) do { \
-		(xx) = _mm_max_epu8((xx), _mm_srli_si128((xx), 8)); \
-		(xx) = _mm_max_epu8((xx), _mm_srli_si128((xx), 4)); \
-		(xx) = _mm_max_epu8((xx), _mm_srli_si128((xx), 2)); \
-		(xx) = _mm_max_epu8((xx), _mm_srli_si128((xx), 1)); \
-    	(ret) = _mm_extract_epi16((xx), 0) & 0x00ff; \
+		(xx) = vec_max16ub((xx), vec_shiftrightbytes1q((xx), 8)); \
+		(xx) = vec_max16ub((xx), vec_shiftrightbytes1q((xx), 4)); \
+		(xx) = vec_max16ub((xx), vec_shiftrightbytes1q((xx), 2)); \
+		(xx) = vec_max16ub((xx), vec_shiftrightbytes1q((xx), 1)); \
+    	(ret) = vec_extract8sh((xx), 0) & 0x00ff; \
 	} while (0)
 
 	// initialization
 	m_b = n_b = 0; b = 0;
-	zero = _mm_set1_epi32(0);
-	gapoe = _mm_set1_epi8(a->gapo + a->gape);
-	gape = _mm_set1_epi8(a->gape);
-	shift = _mm_set1_epi8(q->shift);
+	zero = vec_splat4sw(0);
+	gapoe = vec_splat16sb(a->gapo + a->gape);
+	gape = vec_splat16sb(a->gape);
+	shift = vec_splat16sb(q->shift);
 	H0 = q->H0; H1 = q->H1; E = q->E; Hmax = q->Hmax;
 	slen = q->slen;
 	for (i = 0; i < slen; ++i) {
-		_mm_store_si128(E + i, zero);
-		_mm_store_si128(H0 + i, zero);
-		_mm_store_si128(Hmax + i, zero);
+		vec_store1q(E + i, zero);
+		vec_store1q(H0 + i, zero);
+		vec_store1q(Hmax + i, zero);
 	}
 	// the core loop
 	for (i = 0; i < tlen; ++i) {
 		int j, k, cmp, imax;
 		__m128i e, h, f = zero, max = zero, *S = q->qp + target[i] * slen; // s is the 1st score vector
-		h = _mm_load_si128(H0 + slen - 1); // h={2,5,8,11,14,17,-1,-1} in the above example
-		h = _mm_slli_si128(h, 1); // h=H(i-1,-1); << instead of >> because x64 is little-endian
+		h = vec_load1q(H0 + slen - 1); // h={2,5,8,11,14,17,-1,-1} in the above example
+		h = vec_shiftleftbytes1q(h, 1); // h=H(i-1,-1); << instead of >> because x64 is little-endian
 		for (j = 0; LIKELY(j < slen); ++j) {
 			/* SW cells are computed in the following order:
 			 *   H(i,j)   = max{H(i-1,j-1)+S(i,j), E(i,j), F(i,j)}
@@ -131,34 +131,34 @@
 			 *   F(i,j+1) = max{H(i,j)-q, F(i,j)-r}
 			 */
 			// compute H'(i,j); note that at the beginning, h=H'(i-1,j-1)
-			h = _mm_adds_epu8(h, _mm_load_si128(S + j));
-			h = _mm_subs_epu8(h, shift); // h=H'(i-1,j-1)+S(i,j)
-			e = _mm_load_si128(E + j); // e=E'(i,j)
-			h = _mm_max_epu8(h, e);
-			h = _mm_max_epu8(h, f); // h=H'(i,j)
-			max = _mm_max_epu8(max, h); // set max
-			_mm_store_si128(H1 + j, h); // save to H'(i,j)
+			h = vec_addsaturating16ub(h, vec_load1q(S + j));
+			h = vec_subtractsaturating16ub(h, shift); // h=H'(i-1,j-1)+S(i,j)
+			e = vec_load1q(E + j); // e=E'(i,j)
+			h = vec_max16ub(h, e);
+			h = vec_max16ub(h, f); // h=H'(i,j)
+			max = vec_max16ub(max, h); // set max
+			vec_store1q(H1 + j, h); // save to H'(i,j)
 			// now compute E'(i+1,j)
-			h = _mm_subs_epu8(h, gapoe); // h=H'(i,j)-gapo
-			e = _mm_subs_epu8(e, gape); // e=E'(i,j)-gape
-			e = _mm_max_epu8(e, h); // e=E'(i+1,j)
-			_mm_store_si128(E + j, e); // save to E'(i+1,j)
+			h = vec_subtractsaturating16ub(h, gapoe); // h=H'(i,j)-gapo
+			e = vec_subtractsaturating16ub(e, gape); // e=E'(i,j)-gape
+			e = vec_max16ub(e, h); // e=E'(i+1,j)
+			vec_store1q(E + j, e); // save to E'(i+1,j)
 			// now compute F'(i,j+1)
-			f = _mm_subs_epu8(f, gape);
-			f = _mm_max_epu8(f, h);
+			f = vec_subtractsaturating16ub(f, gape);
+			f = vec_max16ub(f, h);
 			// get H'(i-1,j) and prepare for the next j
-			h = _mm_load_si128(H0 + j); // h=H'(i-1,j)
+			h = vec_load1q(H0 + j); // h=H'(i-1,j)
 		}
 		// NB: we do not need to set E(i,j) as we disallow adjecent insertion and then deletion
 		for (k = 0; LIKELY(k < 16); ++k) { // this block mimics SWPS3; NB: H(i,j) updated in the lazy-F loop cannot exceed max
-			f = _mm_slli_si128(f, 1);
+			f = vec_shiftleftbytes1q(f, 1);
 			for (j = 0; LIKELY(j < slen); ++j) {
-				h = _mm_load_si128(H1 + j);
-				h = _mm_max_epu8(h, f); // h=H'(i,j)
-				_mm_store_si128(H1 + j, h);
-				h = _mm_subs_epu8(h, gapoe);
-				f = _mm_subs_epu8(f, gape);
-				cmp = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_subs_epu8(f, h), zero));
+				h = vec_load1q(H1 + j);
+				h = vec_max16ub(h, f); // h=H'(i,j)
+				vec_store1q(H1 + j, h);
+				h = vec_subtractsaturating16ub(h, gapoe);
+				f = vec_subtractsaturating16ub(f, gape);
+				cmp = vec_extractupperbit16sb(vec_compareeq16sb(vec_subtractsaturating16ub(f, h), zero));
 				if (UNLIKELY(cmp == 0xffff)) goto end_loop16;
 			}
 		}
@@ -177,7 +177,7 @@
 		if (imax > gmax) {
 			gmax = imax; te = i; // te is the end position on the target
 			for (j = 0; LIKELY(j < slen); ++j) // keep the H1 vector
-				_mm_store_si128(Hmax + j, _mm_load_si128(H1 + j));
+				vec_store1q(Hmax + j, vec_load1q(H1 + j));
 			if (gmax + q->shift >= 255) break;
 		}
 		S = H1; H1 = H0; H0 = S; // swap H0 and H1
@@ -208,54 +208,54 @@
 	__m128i zero, gapoe, gape, *H0, *H1, *E, *Hmax;
 
 #define __max_8(ret, xx) do { \
-		(xx) = _mm_max_epi16((xx), _mm_srli_si128((xx), 8)); \
-		(xx) = _mm_max_epi16((xx), _mm_srli_si128((xx), 4)); \
-		(xx) = _mm_max_epi16((xx), _mm_srli_si128((xx), 2)); \
-    	(ret) = _mm_extract_epi16((xx), 0); \
+		(xx) = vec_max8sh((xx), vec_shiftrightbytes1q((xx), 8)); \
+		(xx) = vec_max8sh((xx), vec_shiftrightbytes1q((xx), 4)); \
+		(xx) = vec_max8sh((xx), vec_shiftrightbytes1q((xx), 2)); \
+    	(ret) = vec_extract8sh((xx), 0); \
 	} while (0)
 
 	// initialization
 	m_b = n_b = 0; b = 0;
-	zero = _mm_set1_epi32(0);
-	gapoe = _mm_set1_epi16(a->gapo + a->gape);
-	gape = _mm_set1_epi16(a->gape);
+	zero = vec_splat4sw(0);
+	gapoe = vec_splat8sh(a->gapo + a->gape);
+	gape = vec_splat8sh(a->gape);
 	H0 = q->H0; H1 = q->H1; E = q->E; Hmax = q->Hmax;
 	slen = q->slen;
 	for (i = 0; i < slen; ++i) {
-		_mm_store_si128(E + i, zero);
-		_mm_store_si128(H0 + i, zero);
-		_mm_store_si128(Hmax + i, zero);
+		vec_store1q(E + i, zero);
+		vec_store1q(H0 + i, zero);
+		vec_store1q(Hmax + i, zero);
 	}
 	// the core loop
 	for (i = 0; i < tlen; ++i) {
 		int j, k, imax;
 		__m128i e, h, f = zero, max = zero, *S = q->qp + target[i] * slen; // s is the 1st score vector
-		h = _mm_load_si128(H0 + slen - 1); // h={2,5,8,11,14,17,-1,-1} in the above example
-		h = _mm_slli_si128(h, 2);
+		h = vec_load1q(H0 + slen - 1); // h={2,5,8,11,14,17,-1,-1} in the above example
+		h = vec_shiftleftbytes1q(h, 2);
 		for (j = 0; LIKELY(j < slen); ++j) {
-			h = _mm_adds_epi16(h, *S++);
-			e = _mm_load_si128(E + j);
-			h = _mm_max_epi16(h, e);
-			h = _mm_max_epi16(h, f);
-			max = _mm_max_epi16(max, h);
-			_mm_store_si128(H1 + j, h);
-			h = _mm_subs_epu16(h, gapoe);
-			e = _mm_subs_epu16(e, gape);
-			e = _mm_max_epi16(e, h);
-			_mm_store_si128(E + j, e);
-			f = _mm_subs_epu16(f, gape);
-			f = _mm_max_epi16(f, h);
-			h = _mm_load_si128(H0 + j);
+			h = vec_addsaturating8sh(h, *S++);
+			e = vec_load1q(E + j);
+			h = vec_max8sh(h, e);
+			h = vec_max8sh(h, f);
+			max = vec_max8sh(max, h);
+			vec_store1q(H1 + j, h);
+			h = vec_subtractsaturating8uh(h, gapoe);
+			e = vec_subtractsaturating8uh(e, gape);
+			e = vec_max8sh(e, h);
+			vec_store1q(E + j, e);
+			f = vec_subtractsaturating8uh(f, gape);
+			f = vec_max8sh(f, h);
+			h = vec_load1q(H0 + j);
 		}
 		for (k = 0; LIKELY(k < 16); ++k) {
-			f = _mm_slli_si128(f, 2);
+			f = vec_shiftleftbytes1q(f, 2);
 			for (j = 0; LIKELY(j < slen); ++j) {
-				h = _mm_load_si128(H1 + j);
-				h = _mm_max_epi16(h, f);
-				_mm_store_si128(H1 + j, h);
-				h = _mm_subs_epu16(h, gapoe);
-				f = _mm_subs_epu16(f, gape);
-				if(UNLIKELY(!_mm_movemask_epi8(_mm_cmpgt_epi16(f, h)))) goto end_loop8;
+				h = vec_load1q(H1 + j);
+				h = vec_max8sh(h, f);
+				vec_store1q(H1 + j, h);
+				h = vec_subtractsaturating8uh(h, gapoe);
+				f = vec_subtractsaturating8uh(f, gape);
+				if(UNLIKELY(!vec_extractupperbit16sb(vec_comparegt8sh(f, h)))) goto end_loop8;
 			}
 		}
 end_loop8:
@@ -272,7 +272,7 @@
 		if (imax > gmax) {
 			gmax = imax; te = i;
 			for (j = 0; LIKELY(j < slen); ++j)
-				_mm_store_si128(Hmax + j, _mm_load_si128(H1 + j));
+				vec_store1q(Hmax + j, vec_load1q(H1 + j));
 		}
 		S = H1; H1 = H0; H0 = S;
 	}
