--- ext/include/ConsensusCore/LFloat.hpp
+++ ext/include/ConsensusCore/LFloat.hpp
@@ -36,7 +36,12 @@
 // Author: David Alexander
 
 #pragma once
-#include <xmmintrin.h>
+
+#include <vec128sp.h>
+// Undef to prevent these <altivec.h> defines from colliding with C++ keywords
+#undef bool
+#undef vector
+
 #include <cfloat>
 #include <ostream>
 
@@ -74,6 +79,6 @@
     };
 
     template<typename T>  const float  Zero()  { return T(); }
-    template<typename T>  const __m128 Zero4() { return _mm_set_ps1(T()); }
+    template<typename T>  const __m128 Zero4() { return vec_splat4sp(T()); }
 }
 
--- ext/include/ConsensusCore/Matrix/DenseMatrix-inl.hpp
+++ ext/include/ConsensusCore/Matrix/DenseMatrix-inl.hpp
@@ -157,7 +157,7 @@
     DenseMatrix::Get4(int i, int j) const
     {
         assert(0 <= i && i <= Rows() - 4);
-        return _mm_loadu_ps(&boost_dense_matrix::operator()(i, j).value);
+        return vec_loadu4sp(&boost_dense_matrix::operator()(i, j).value);
     }
 
     inline void
@@ -165,7 +165,7 @@
     {
         assert(columnBeingEdited_ == j);
         assert(0 <= i && i <= Rows() - 4);
-        _mm_storeu_ps(&boost_dense_matrix::operator()(i, j).value, v4);
+        vec_storeu4sp(&boost_dense_matrix::operator()(i, j).value, v4);
     }
 }
 
--- ext/include/ConsensusCore/Matrix/DenseMatrix.hpp
+++ ext/include/ConsensusCore/Matrix/DenseMatrix.hpp
@@ -37,7 +37,10 @@
 
 #pragma once
 
-#include <xmmintrin.h>
+#include <vec128sp.h>
+// Undef to prevent these <altivec.h> defines from colliding with C++ keywords
+#undef bool
+#undef vector
 
 #include <boost/numeric/ublas/matrix.hpp>
 #include <utility>
--- ext/include/ConsensusCore/Matrix/SparseMatrix.hpp
+++ ext/include/ConsensusCore/Matrix/SparseMatrix.hpp
@@ -37,7 +37,11 @@
 
 #pragma once
 
-#include <xmmintrin.h>
+#include <vec128sp.h>
+// Undef to prevent these <altivec.h> defines from colliding with C++ keywords
+#undef bool
+#undef vector
+
 #include <utility>
 #include <vector>
 
--- ext/include/ConsensusCore/Matrix/SparseVector-inl.hpp
+++ ext/include/ConsensusCore/Matrix/SparseVector-inl.hpp
@@ -175,11 +175,11 @@
         assert(i >= 0 && i < logicalLength_ - 3);
         if (i >= allocatedBeginRow_ && i < allocatedEndRow_ - 3)
         {
-            return _mm_loadu_ps(&(*storage_)[i-allocatedBeginRow_]);
+            return vec_loadu4sp(&(*storage_)[i-allocatedBeginRow_]);
         }
         else
         {
-            return _mm_set_ps(Get(i+3), Get(i+2), Get(i+1), Get(i+0));
+            return vec_set4sp(Get(i+3), Get(i+2), Get(i+1), Get(i+0));
         }
     }
 
@@ -189,12 +189,12 @@
         assert(i >= 0 && i < logicalLength_ - 3);
         if (i >= allocatedBeginRow_ && i < allocatedEndRow_ - 3)
         {
-            _mm_storeu_ps(&(*storage_)[i-allocatedBeginRow_], v4);
+            vec_storeu4sp(&(*storage_)[i-allocatedBeginRow_], v4);
         }
         else
         {
             float vbuf[4];
-            _mm_storeu_ps(vbuf, v4);
+            vec_storeu4sp(vbuf, v4);
             Set(i+0, vbuf[0]);
             Set(i+1, vbuf[1]);
             Set(i+2, vbuf[2]);
--- ext/include/ConsensusCore/Matrix/SparseVector.hpp
+++ ext/include/ConsensusCore/Matrix/SparseVector.hpp
@@ -37,7 +37,11 @@
 
 #pragma once
 
-#include <xmmintrin.h>
+#include <vec128sp.h>
+// Undef to prevent these <altivec.h> defines from colliding with C++ keywords
+#undef bool
+#undef vector
+
 #include <utility>
 #include <vector>
 
--- ext/include/ssw/ssw.h
+++ ext/include/ssw/ssw.h
@@ -14,7 +14,11 @@
 #include <stdio.h>
 #include <stdint.h>
 #include <string.h>
-#include <emmintrin.h>
+
+#include <vec128int.h>
+// Undef to prevent these <altivec.h> defines from colliding with C++ keywords
+#undef bool
+#undef vector
 
 #ifdef __cplusplus
 extern "C" {
--- ext/src/bwa/ksw.c
+++ ext/src/bwa/ksw.c
@@ -26,7 +26,7 @@
 #include <stdlib.h>
 #include <stdint.h>
 #include <assert.h>
-#include <emmintrin.h>
+#include <vec128int.h>
 #include "ksw.h"
 
 #ifdef USE_MALLOC_WRAPPERS
@@ -116,11 +116,11 @@
 	kswr_t r;
 
 #define __max_16(ret, xx) do { \
-		(xx) = _mm_max_epu8((xx), _mm_srli_si128((xx), 8)); \
-		(xx) = _mm_max_epu8((xx), _mm_srli_si128((xx), 4)); \
-		(xx) = _mm_max_epu8((xx), _mm_srli_si128((xx), 2)); \
-		(xx) = _mm_max_epu8((xx), _mm_srli_si128((xx), 1)); \
-    	(ret) = _mm_extract_epi16((xx), 0) & 0x00ff; \
+		(xx) = vec_max16ub((xx), vec_shiftrightbytes1q((xx), 8)); \
+		(xx) = vec_max16ub((xx), vec_shiftrightbytes1q((xx), 4)); \
+		(xx) = vec_max16ub((xx), vec_shiftrightbytes1q((xx), 2)); \
+		(xx) = vec_max16ub((xx), vec_shiftrightbytes1q((xx), 1)); \
+    	(ret) = vec_extract8sh((xx), 0) & 0x00ff; \
 	} while (0)
 
 	// initialization
@@ -128,25 +128,25 @@
 	minsc = (xtra&KSW_XSUBO)? xtra&0xffff : 0x10000;
 	endsc = (xtra&KSW_XSTOP)? xtra&0xffff : 0x10000;
 	m_b = n_b = 0; b = 0;
-	zero = _mm_set1_epi32(0);
-	oe_del = _mm_set1_epi8(_o_del + _e_del);
-	e_del = _mm_set1_epi8(_e_del);
-	oe_ins = _mm_set1_epi8(_o_ins + _e_ins);
-	e_ins = _mm_set1_epi8(_e_ins);
-	shift = _mm_set1_epi8(q->shift);
+	zero = vec_splat4sw(0);
+	oe_del = vec_splat16sb(_o_del + _e_del);
+	e_del = vec_splat16sb(_e_del);
+	oe_ins = vec_splat16sb(_o_ins + _e_ins);
+	e_ins = vec_splat16sb(_e_ins);
+	shift = vec_splat16sb(q->shift);
 	H0 = q->H0; H1 = q->H1; E = q->E; Hmax = q->Hmax;
 	slen = q->slen;
 	for (i = 0; i < slen; ++i) {
-		_mm_store_si128(E + i, zero);
-		_mm_store_si128(H0 + i, zero);
-		_mm_store_si128(Hmax + i, zero);
+		vec_store1q(E + i, zero);
+		vec_store1q(H0 + i, zero);
+		vec_store1q(Hmax + i, zero);
 	}
 	// the core loop
 	for (i = 0; i < tlen; ++i) {
 		int j, k, cmp, imax;
 		__m128i e, h, t, f = zero, max = zero, *S = q->qp + target[i] * slen; // s is the 1st score vector
-		h = _mm_load_si128(H0 + slen - 1); // h={2,5,8,11,14,17,-1,-1} in the above example
-		h = _mm_slli_si128(h, 1); // h=H(i-1,-1); << instead of >> because x64 is little-endian
+		h = vec_load1q(H0 + slen - 1); // h={2,5,8,11,14,17,-1,-1} in the above example
+		h = vec_shiftleftbytes1q(h, 1); // h=H(i-1,-1); << instead of >> because x64 is little-endian
 		for (j = 0; LIKELY(j < slen); ++j) {
 			/* SW cells are computed in the following order:
 			 *   H(i,j)   = max{H(i-1,j-1)+S(i,j), E(i,j), F(i,j)}
@@ -154,35 +154,35 @@
 			 *   F(i,j+1) = max{H(i,j)-q, F(i,j)-r}
 			 */
 			// compute H'(i,j); note that at the beginning, h=H'(i-1,j-1)
-			h = _mm_adds_epu8(h, _mm_load_si128(S + j));
-			h = _mm_subs_epu8(h, shift); // h=H'(i-1,j-1)+S(i,j)
-			e = _mm_load_si128(E + j); // e=E'(i,j)
-			h = _mm_max_epu8(h, e);
-			h = _mm_max_epu8(h, f); // h=H'(i,j)
-			max = _mm_max_epu8(max, h); // set max
-			_mm_store_si128(H1 + j, h); // save to H'(i,j)
+			h = vec_addsaturating16ub(h, vec_load1q(S + j));
+			h = vec_subtractsaturating16ub(h, shift); // h=H'(i-1,j-1)+S(i,j)
+			e = vec_load1q(E + j); // e=E'(i,j)
+			h = vec_max16ub(h, e);
+			h = vec_max16ub(h, f); // h=H'(i,j)
+			max = vec_max16ub(max, h); // set max
+			vec_store1q(H1 + j, h); // save to H'(i,j)
 			// now compute E'(i+1,j)
-			e = _mm_subs_epu8(e, e_del); // e=E'(i,j) - e_del
-			t = _mm_subs_epu8(h, oe_del); // h=H'(i,j) - o_del - e_del
-			e = _mm_max_epu8(e, t); // e=E'(i+1,j)
-			_mm_store_si128(E + j, e); // save to E'(i+1,j)
+			e = vec_subtractsaturating16ub(e, e_del); // e=E'(i,j) - e_del
+			t = vec_subtractsaturating16ub(h, oe_del); // h=H'(i,j) - o_del - e_del
+			e = vec_max16ub(e, t); // e=E'(i+1,j)
+			vec_store1q(E + j, e); // save to E'(i+1,j)
 			// now compute F'(i,j+1)
-			f = _mm_subs_epu8(f, e_ins);
-			t = _mm_subs_epu8(h, oe_ins); // h=H'(i,j) - o_ins - e_ins
-			f = _mm_max_epu8(f, t);
+			f = vec_subtractsaturating16ub(f, e_ins);
+			t = vec_subtractsaturating16ub(h, oe_ins); // h=H'(i,j) - o_ins - e_ins
+			f = vec_max16ub(f, t);
 			// get H'(i-1,j) and prepare for the next j
-			h = _mm_load_si128(H0 + j); // h=H'(i-1,j)
+			h = vec_load1q(H0 + j); // h=H'(i-1,j)
 		}
 		// NB: we do not need to set E(i,j) as we disallow adjecent insertion and then deletion
 		for (k = 0; LIKELY(k < 16); ++k) { // this block mimics SWPS3; NB: H(i,j) updated in the lazy-F loop cannot exceed max
-			f = _mm_slli_si128(f, 1);
+			f = vec_shiftleftbytes1q(f, 1);
 			for (j = 0; LIKELY(j < slen); ++j) {
-				h = _mm_load_si128(H1 + j);
-				h = _mm_max_epu8(h, f); // h=H'(i,j)
-				_mm_store_si128(H1 + j, h);
-				h = _mm_subs_epu8(h, oe_ins);
-				f = _mm_subs_epu8(f, e_ins);
-				cmp = _mm_movemask_epi8(_mm_cmpeq_epi8(_mm_subs_epu8(f, h), zero));
+				h = vec_load1q(H1 + j);
+				h = vec_max16ub(h, f); // h=H'(i,j)
+				vec_store1q(H1 + j, h);
+				h = vec_subtractsaturating16ub(h, oe_ins);
+				f = vec_subtractsaturating16ub(f, e_ins);
+				cmp = vec_extractupperbit16sb(vec_compareeq16sb(vec_subtractsaturating16ub(f, h), zero));
 				if (UNLIKELY(cmp == 0xffff)) goto end_loop16;
 			}
 		}
@@ -201,7 +201,7 @@
 		if (imax > gmax) {
 			gmax = imax; te = i; // te is the end position on the target
 			for (j = 0; LIKELY(j < slen); ++j) // keep the H1 vector
-				_mm_store_si128(Hmax + j, _mm_load_si128(H1 + j));
+				vec_store1q(Hmax + j, vec_load1q(H1 + j));
 			if (gmax + q->shift >= 255 || gmax >= endsc) break;
 		}
 		S = H1; H1 = H0; H0 = S; // swap H0 and H1
@@ -237,10 +237,10 @@
 	kswr_t r;
 
 #define __max_8(ret, xx) do { \
-		(xx) = _mm_max_epi16((xx), _mm_srli_si128((xx), 8)); \
-		(xx) = _mm_max_epi16((xx), _mm_srli_si128((xx), 4)); \
-		(xx) = _mm_max_epi16((xx), _mm_srli_si128((xx), 2)); \
-    	(ret) = _mm_extract_epi16((xx), 0); \
+		(xx) = vec_max8sh((xx), vec_shiftrightbytes1q((xx), 8)); \
+		(xx) = vec_max8sh((xx), vec_shiftrightbytes1q((xx), 4)); \
+		(xx) = vec_max8sh((xx), vec_shiftrightbytes1q((xx), 2)); \
+    	(ret) = vec_extract8sh((xx), 0); \
 	} while (0)
 
 	// initialization
@@ -248,49 +248,49 @@
 	minsc = (xtra&KSW_XSUBO)? xtra&0xffff : 0x10000;
 	endsc = (xtra&KSW_XSTOP)? xtra&0xffff : 0x10000;
 	m_b = n_b = 0; b = 0;
-	zero = _mm_set1_epi32(0);
-	oe_del = _mm_set1_epi16(_o_del + _e_del);
-	e_del = _mm_set1_epi16(_e_del);
-	oe_ins = _mm_set1_epi16(_o_ins + _e_ins);
-	e_ins = _mm_set1_epi16(_e_ins);
+	zero = vec_splat4sw(0);
+	oe_del = vec_splat8sh(_o_del + _e_del);
+	e_del = vec_splat8sh(_e_del);
+	oe_ins = vec_splat8sh(_o_ins + _e_ins);
+	e_ins = vec_splat8sh(_e_ins);
 	H0 = q->H0; H1 = q->H1; E = q->E; Hmax = q->Hmax;
 	slen = q->slen;
 	for (i = 0; i < slen; ++i) {
-		_mm_store_si128(E + i, zero);
-		_mm_store_si128(H0 + i, zero);
-		_mm_store_si128(Hmax + i, zero);
+		vec_store1q(E + i, zero);
+		vec_store1q(H0 + i, zero);
+		vec_store1q(Hmax + i, zero);
 	}
 	// the core loop
 	for (i = 0; i < tlen; ++i) {
 		int j, k, imax;
 		__m128i e, t, h, f = zero, max = zero, *S = q->qp + target[i] * slen; // s is the 1st score vector
-		h = _mm_load_si128(H0 + slen - 1); // h={2,5,8,11,14,17,-1,-1} in the above example
-		h = _mm_slli_si128(h, 2);
+		h = vec_load1q(H0 + slen - 1); // h={2,5,8,11,14,17,-1,-1} in the above example
+		h = vec_shiftleftbytes1q(h, 2);
 		for (j = 0; LIKELY(j < slen); ++j) {
-			h = _mm_adds_epi16(h, *S++);
-			e = _mm_load_si128(E + j);
-			h = _mm_max_epi16(h, e);
-			h = _mm_max_epi16(h, f);
-			max = _mm_max_epi16(max, h);
-			_mm_store_si128(H1 + j, h);
-			e = _mm_subs_epu16(e, e_del);
-			t = _mm_subs_epu16(h, oe_del);
-			e = _mm_max_epi16(e, t);
-			_mm_store_si128(E + j, e);
-			f = _mm_subs_epu16(f, e_ins);
-			t = _mm_subs_epu16(h, oe_ins);
-			f = _mm_max_epi16(f, t);
-			h = _mm_load_si128(H0 + j);
+			h = vec_addsaturating8sh(h, *S++);
+			e = vec_load1q(E + j);
+			h = vec_max8sh(h, e);
+			h = vec_max8sh(h, f);
+			max = vec_max8sh(max, h);
+			vec_store1q(H1 + j, h);
+			e = vec_subtractsaturating8uh(e, e_del);
+			t = vec_subtractsaturating8uh(h, oe_del);
+			e = vec_max8sh(e, t);
+			vec_store1q(E + j, e);
+			f = vec_subtractsaturating8uh(f, e_ins);
+			t = vec_subtractsaturating8uh(h, oe_ins);
+			f = vec_max8sh(f, t);
+			h = vec_load1q(H0 + j);
 		}
 		for (k = 0; LIKELY(k < 16); ++k) {
-			f = _mm_slli_si128(f, 2);
+			f = vec_shiftleftbytes1q(f, 2);
 			for (j = 0; LIKELY(j < slen); ++j) {
-				h = _mm_load_si128(H1 + j);
-				h = _mm_max_epi16(h, f);
-				_mm_store_si128(H1 + j, h);
-				h = _mm_subs_epu16(h, oe_ins);
-				f = _mm_subs_epu16(f, e_ins);
-				if(UNLIKELY(!_mm_movemask_epi8(_mm_cmpgt_epi16(f, h)))) goto end_loop8;
+				h = vec_load1q(H1 + j);
+				h = vec_max8sh(h, f);
+				vec_store1q(H1 + j, h);
+				h = vec_subtractsaturating8uh(h, oe_ins);
+				f = vec_subtractsaturating8uh(f, e_ins);
+				if(UNLIKELY(!vec_extractupperbit16sb(vec_comparegt8sh(f, h)))) goto end_loop8;
 			}
 		}
 end_loop8:
@@ -307,7 +307,7 @@
 		if (imax > gmax) {
 			gmax = imax; te = i;
 			for (j = 0; LIKELY(j < slen); ++j)
-				_mm_store_si128(Hmax + j, _mm_load_si128(H1 + j));
+				vec_store1q(Hmax + j, vec_load1q(H1 + j));
 			if (gmax >= endsc) break;
 		}
 		S = H1; H1 = H0; H0 = S;
--- ext/src/ssw/ssw.c
+++ ext/src/ssw/ssw.c
@@ -35,7 +35,7 @@
  *
  */
 
-#include <emmintrin.h>
+#include <vec128int.h>
 #include <stdint.h>
 #include <stdlib.h>
 #include <stdio.h>
@@ -134,11 +134,11 @@
 	 						 uint8_t bias,  /* Shift 0 point to a positive value. */
 							 int32_t maskLen) {
 
-#define max16(m, vm) (vm) = _mm_max_epu8((vm), _mm_srli_si128((vm), 8)); \
-					  (vm) = _mm_max_epu8((vm), _mm_srli_si128((vm), 4)); \
-					  (vm) = _mm_max_epu8((vm), _mm_srli_si128((vm), 2)); \
-					  (vm) = _mm_max_epu8((vm), _mm_srli_si128((vm), 1)); \
-					  (m) = _mm_extract_epi16((vm), 0)
+#define max16(m, vm) (vm) = vec_max16ub((vm), vec_shiftrightbytes1q((vm), 8)); \
+					  (vm) = vec_max16ub((vm), vec_shiftrightbytes1q((vm), 4)); \
+					  (vm) = vec_max16ub((vm), vec_shiftrightbytes1q((vm), 2)); \
+					  (vm) = vec_max16ub((vm), vec_shiftrightbytes1q((vm), 1)); \
+					  (m) = vec_extract8sh((vm), 0)
 
 	uint8_t max = 0;		                     /* the max alignment score */
 	int32_t end_read = readLen - 1;
@@ -152,7 +152,7 @@
 	int32_t* end_read_column = (int32_t*) calloc(refLen, sizeof(int32_t));
 
 	/* Define 16 byte 0 vector. */
-	__m128i vZero = _mm_set1_epi32(0);
+	__m128i vZero = vec_splat4sw(0);
 
 	__m128i* pvHStore = (__m128i*) calloc(segLen, sizeof(__m128i));
 	__m128i* pvHLoad = (__m128i*) calloc(segLen, sizeof(__m128i));
@@ -161,13 +161,13 @@
 
 	int32_t i, j;
 	/* 16 byte insertion begin vector */
-	__m128i vGapO = _mm_set1_epi8(weight_gapO);
+	__m128i vGapO = vec_splat16sb(weight_gapO);
 
 	/* 16 byte insertion extension vector */
-	__m128i vGapE = _mm_set1_epi8(weight_gapE);
+	__m128i vGapE = vec_splat16sb(weight_gapE);
 
 	/* 16 byte bias vector */
-	__m128i vBias = _mm_set1_epi8(bias);
+	__m128i vBias = vec_splat16sb(bias);
 
 	__m128i vMaxScore = vZero; /* Trace the highest score of the whole SW matrix. */
 	__m128i vMaxMark = vZero; /* Trace the highest score till the previous column. */
@@ -192,7 +192,7 @@
 //		fprintf(stderr, "middle[%d]: %d\n", i, maxColumn[i]);
 
 		__m128i vH = pvHStore[segLen - 1];
-		vH = _mm_slli_si128 (vH, 1); /* Shift the 128-bit value in vH left by 1 byte. */
+		vH = vec_shiftleftbytes1q (vH, 1); /* Shift the 128-bit value in vH left by 1 byte. */
 		const __m128i* vP = vProfile + ref[i] * segLen; /* Right part of the vProfile */
 
 		/* Swap the 2 H buffers. */
@@ -202,8 +202,8 @@
 
 		/* inner loop to process the query sequence */
 		for (j = 0; LIKELY(j < segLen); ++j) {
-			vH = _mm_adds_epu8(vH, _mm_load_si128(vP + j));
-			vH = _mm_subs_epu8(vH, vBias); /* vH will be always > 0 */
+			vH = vec_addsaturating16ub(vH, vec_load1q(vP + j));
+			vH = vec_subtractsaturating16ub(vH, vBias); /* vH will be always > 0 */
 	//	max16(maxColumn[i], vH);
 	//	fprintf(stderr, "H[%d]: %d\n", i, maxColumn[i]);
 //	int8_t* t;
@@ -211,69 +211,69 @@
 //for (t = (int8_t*)&vH, ti = 0; ti < 16; ++ti) fprintf(stderr, "%d\t", *t++);
 
 			/* Get max from vH, vE and vF. */
-			e = _mm_load_si128(pvE + j);
-			vH = _mm_max_epu8(vH, e);
-			vH = _mm_max_epu8(vH, vF);
-			vMaxColumn = _mm_max_epu8(vMaxColumn, vH);
+			e = vec_load1q(pvE + j);
+			vH = vec_max16ub(vH, e);
+			vH = vec_max16ub(vH, vF);
+			vMaxColumn = vec_max16ub(vMaxColumn, vH);
 
 	//	max16(maxColumn[i], vMaxColumn);
 	//	fprintf(stderr, "middle[%d]: %d\n", i, maxColumn[i]);
 //	for (t = (int8_t*)&vMaxColumn, ti = 0; ti < 16; ++ti) fprintf(stderr, "%d\t", *t++);
 
 			/* Save vH values. */
-			_mm_store_si128(pvHStore + j, vH);
+			vec_store1q(pvHStore + j, vH);
 
 			/* Update vE value. */
-			vH = _mm_subs_epu8(vH, vGapO); /* saturation arithmetic, result >= 0 */
-			e = _mm_subs_epu8(e, vGapE);
-			e = _mm_max_epu8(e, vH);
-			_mm_store_si128(pvE + j, e);
+			vH = vec_subtractsaturating16ub(vH, vGapO); /* saturation arithmetic, result >= 0 */
+			e = vec_subtractsaturating16ub(e, vGapE);
+			e = vec_max16ub(e, vH);
+			vec_store1q(pvE + j, e);
 
 			/* Update vF value. */
-			vF = _mm_subs_epu8(vF, vGapE);
-			vF = _mm_max_epu8(vF, vH);
+			vF = vec_subtractsaturating16ub(vF, vGapE);
+			vF = vec_max16ub(vF, vH);
 
 			/* Load the next vH. */
-			vH = _mm_load_si128(pvHLoad + j);
+			vH = vec_load1q(pvHLoad + j);
 		}
 
 		/* Lazy_F loop: has been revised to disallow adjecent insertion and then deletion, so don't update E(i, j), learn from SWPS3 */
         /* reset pointers to the start of the saved data */
         j = 0;
-        vH = _mm_load_si128 (pvHStore + j);
+        vH = vec_load1q (pvHStore + j);
 
         /*  the computed vF value is for the given column.  since */
         /*  we are at the end, we need to shift the vF value over */
         /*  to the next column. */
-        vF = _mm_slli_si128 (vF, 1);
-        vTemp = _mm_subs_epu8 (vH, vGapO);
-		vTemp = _mm_subs_epu8 (vF, vTemp);
-		vTemp = _mm_cmpeq_epi8 (vTemp, vZero);
-		cmp  = _mm_movemask_epi8 (vTemp);
+        vF = vec_shiftleftbytes1q (vF, 1);
+        vTemp = vec_subtractsaturating16ub (vH, vGapO);
+		vTemp = vec_subtractsaturating16ub (vF, vTemp);
+		vTemp = vec_compareeq16sb (vTemp, vZero);
+		cmp  = vec_extractupperbit16sb (vTemp);
 
         while (cmp != 0xffff)
         {
-            vH = _mm_max_epu8 (vH, vF);
-			vMaxColumn = _mm_max_epu8(vMaxColumn, vH);
-            _mm_store_si128 (pvHStore + j, vH);
-            vF = _mm_subs_epu8 (vF, vGapE);
+            vH = vec_max16ub (vH, vF);
+			vMaxColumn = vec_max16ub(vMaxColumn, vH);
+            vec_store1q (pvHStore + j, vH);
+            vF = vec_subtractsaturating16ub (vF, vGapE);
             j++;
             if (j >= segLen)
             {
                 j = 0;
-                vF = _mm_slli_si128 (vF, 1);
+                vF = vec_shiftleftbytes1q (vF, 1);
             }
-            vH = _mm_load_si128 (pvHStore + j);
+            vH = vec_load1q (pvHStore + j);
 
-            vTemp = _mm_subs_epu8 (vH, vGapO);
-            vTemp = _mm_subs_epu8 (vF, vTemp);
-            vTemp = _mm_cmpeq_epi8 (vTemp, vZero);
-            cmp  = _mm_movemask_epi8 (vTemp);
+            vTemp = vec_subtractsaturating16ub (vH, vGapO);
+            vTemp = vec_subtractsaturating16ub (vF, vTemp);
+            vTemp = vec_compareeq16sb (vTemp, vZero);
+            cmp  = vec_extractupperbit16sb (vTemp);
         }
 
-		vMaxScore = _mm_max_epu8(vMaxScore, vMaxColumn);
-		vTemp = _mm_cmpeq_epi8(vMaxMark, vMaxScore);
-		cmp = _mm_movemask_epi8(vTemp);
+		vMaxScore = vec_max16ub(vMaxScore, vMaxColumn);
+		vTemp = vec_compareeq16sb(vMaxMark, vMaxScore);
+		cmp = vec_extractupperbit16sb(vTemp);
 		if (cmp != 0xffff) {
 			uint8_t temp;
 			vMaxMark = vMaxScore;
@@ -378,10 +378,10 @@
 							 uint16_t terminate,
 							 int32_t maskLen) {
 
-#define max8(m, vm) (vm) = _mm_max_epi16((vm), _mm_srli_si128((vm), 8)); \
-					(vm) = _mm_max_epi16((vm), _mm_srli_si128((vm), 4)); \
-					(vm) = _mm_max_epi16((vm), _mm_srli_si128((vm), 2)); \
-					(m) = _mm_extract_epi16((vm), 0)
+#define max8(m, vm) (vm) = vec_max8sh((vm), vec_shiftrightbytes1q((vm), 8)); \
+					(vm) = vec_max8sh((vm), vec_shiftrightbytes1q((vm), 4)); \
+					(vm) = vec_max8sh((vm), vec_shiftrightbytes1q((vm), 2)); \
+					(m) = vec_extract8sh((vm), 0)
 
 	uint16_t max = 0;		                     /* the max alignment score */
 	int32_t end_read = readLen - 1;
@@ -395,7 +395,7 @@
 	int32_t* end_read_column = (int32_t*) calloc(refLen, sizeof(int32_t));
 
 	/* Define 16 byte 0 vector. */
-	__m128i vZero = _mm_set1_epi32(0);
+	__m128i vZero = vec_splat4sw(0);
 
 	__m128i* pvHStore = (__m128i*) calloc(segLen, sizeof(__m128i));
 	__m128i* pvHLoad = (__m128i*) calloc(segLen, sizeof(__m128i));
@@ -404,10 +404,10 @@
 
 	int32_t i, j, k;
 	/* 16 byte insertion begin vector */
-	__m128i vGapO = _mm_set1_epi16(weight_gapO);
+	__m128i vGapO = vec_splat8sh(weight_gapO);
 
 	/* 16 byte insertion extension vector */
-	__m128i vGapE = _mm_set1_epi16(weight_gapE);
+	__m128i vGapE = vec_splat8sh(weight_gapE);
 
 	__m128i vMaxScore = vZero; /* Trace the highest score of the whole SW matrix. */
 	__m128i vMaxMark = vZero; /* Trace the highest score till the previous column. */
@@ -426,7 +426,7 @@
 							   Any errors to vH values will be corrected in the Lazy_F loop.
 							 */
 		__m128i vH = pvHStore[segLen - 1];
-		vH = _mm_slli_si128 (vH, 2); /* Shift the 128-bit value in vH left by 2 byte. */
+		vH = vec_shiftleftbytes1q (vH, 2); /* Shift the 128-bit value in vH left by 2 byte. */
 
 		/* Swap the 2 H buffers. */
 		__m128i* pv = pvHLoad;
@@ -439,49 +439,49 @@
 
 		/* inner loop to process the query sequence */
 		for (j = 0; LIKELY(j < segLen); j ++) {
-			vH = _mm_adds_epi16(vH, _mm_load_si128(vP + j));
+			vH = vec_addsaturating8sh(vH, vec_load1q(vP + j));
 
 			/* Get max from vH, vE and vF. */
-			e = _mm_load_si128(pvE + j);
-			vH = _mm_max_epi16(vH, e);
-			vH = _mm_max_epi16(vH, vF);
-			vMaxColumn = _mm_max_epi16(vMaxColumn, vH);
+			e = vec_load1q(pvE + j);
+			vH = vec_max8sh(vH, e);
+			vH = vec_max8sh(vH, vF);
+			vMaxColumn = vec_max8sh(vMaxColumn, vH);
 
 			/* Save vH values. */
-			_mm_store_si128(pvHStore + j, vH);
+			vec_store1q(pvHStore + j, vH);
 
 			/* Update vE value. */
-			vH = _mm_subs_epu16(vH, vGapO); /* saturation arithmetic, result >= 0 */
-			e = _mm_subs_epu16(e, vGapE);
-			e = _mm_max_epi16(e, vH);
-			_mm_store_si128(pvE + j, e);
+			vH = vec_subtractsaturating8uh(vH, vGapO); /* saturation arithmetic, result >= 0 */
+			e = vec_subtractsaturating8uh(e, vGapE);
+			e = vec_max8sh(e, vH);
+			vec_store1q(pvE + j, e);
 
 			/* Update vF value. */
-			vF = _mm_subs_epu16(vF, vGapE);
-			vF = _mm_max_epi16(vF, vH);
+			vF = vec_subtractsaturating8uh(vF, vGapE);
+			vF = vec_max8sh(vF, vH);
 
 			/* Load the next vH. */
-			vH = _mm_load_si128(pvHLoad + j);
+			vH = vec_load1q(pvHLoad + j);
 		}
 
 		/* Lazy_F loop: has been revised to disallow adjecent insertion and then deletion, so don't update E(i, j), learn from SWPS3 */
 		for (k = 0; LIKELY(k < 8); ++k) {
-			vF = _mm_slli_si128 (vF, 2);
+			vF = vec_shiftleftbytes1q (vF, 2);
 			for (j = 0; LIKELY(j < segLen); ++j) {
-				vH = _mm_load_si128(pvHStore + j);
-				vH = _mm_max_epi16(vH, vF);
-        vMaxColumn = _mm_max_epi16(vMaxColumn, vH);
-        _mm_store_si128(pvHStore + j, vH);
-				vH = _mm_subs_epu16(vH, vGapO);
-				vF = _mm_subs_epu16(vF, vGapE);
-				if (UNLIKELY(! _mm_movemask_epi8(_mm_cmpgt_epi16(vF, vH)))) goto end;
+				vH = vec_load1q(pvHStore + j);
+				vH = vec_max8sh(vH, vF);
+        vMaxColumn = vec_max8sh(vMaxColumn, vH);
+        vec_store1q(pvHStore + j, vH);
+				vH = vec_subtractsaturating8uh(vH, vGapO);
+				vF = vec_subtractsaturating8uh(vF, vGapE);
+				if (UNLIKELY(! vec_extractupperbit16sb(vec_comparegt8sh(vF, vH)))) goto end;
 			}
 		}
 
 end:
-		vMaxScore = _mm_max_epi16(vMaxScore, vMaxColumn);
-		vTemp = _mm_cmpeq_epi16(vMaxMark, vMaxScore);
-		cmp = _mm_movemask_epi8(vTemp);
+		vMaxScore = vec_max8sh(vMaxScore, vMaxColumn);
+		vTemp = vec_compareeq8sh(vMaxMark, vMaxScore);
+		cmp = vec_extractupperbit16sb(vTemp);
 		if (cmp != 0xffff) {
 			uint16_t temp;
 			vMaxMark = vMaxScore;
